#!/bin/bash
# Modos:
# * Resumen: si no tienen contenido, crear un unico mail con todos los
#   titulares mas los resumenes
# * Completo: un mail por post completo
# Cuando se une un feed por primera vez se manda el mail de bienvenida, y el
# resto de posts se responde sobre ese hilo.

STRIPHTML=${STRIPHTML:-false}

hash_table="$(dirname $(readlink -f $0))/feeds.tch"

[ ! -f "$hash_table" ] && tcamgr create "$hash_table"

msg() {
  printf "$1\n" "$2" 1>&2
}

sel() {
  xml sel -N content=http://purl.org/rss/1.0/modules/content/ \
          -N feedburner=http://rssnamespace.org/feedburner/ext/1.0 \
          -N creativeCommons=http://backend.userland.com/creativeCommonsRssModule 
}

get() {
  tcamgr get ${hash_table} $1 2>/dev/null
  return $?
}

put() {
  tcamgr put ${hash_table} $1 $2 2>/dev/null
  return $?
}

count() {
  c=$(xml sel -E utf-8 -T -t -v "count(/rss/channel/item)" "$1" || echo 0)
  msg "Counting items: %d" $c

  echo $c
}

# Returns feed name from url
# accepts pipe and $1
feed() {
  if [ -z "$1" ] ; then 
    sed "s/[^a-z0-9]//g" </dev/stdin # | \
#    sha256sum | cut -d " " -f1
  else
    echo "$1" | feed
  fi
}

# Perform cleanups
# Currently converts HTML entities to text and removes feedburner ads
cleanup() {
  msg "Cleaning up"
#  recode html..iso-8859-1 </dev/stdin | \
  sed "/<div class=\"feedflare\">/,/<\/div>/d" </dev/stdin | \
  pandoc -f html -t markdown --reference-links --smart
}

# Detect wether the feed is {content,summary,emtpy}
feed_type() {
  msg "$1 $2"
  ret="$(get "${2}_type")"

  if [ -z "$ret" ]; then
    ret="$(xml sel -N content=http://purl.org/rss/1.0/modules/content/ \
                   -E utf-8 -T \
                   -t -m /rss/channel/item \
                   --if "content:encoded" \
                   -o "content" -n \
                   --elif "description" \
                   -o "summary" -n \
                   --else -o "empty" -n \
                   "$1" | head -n1)"

    put "${2}_type" "$ret"
  fi

  msg "Getting feed type: %s" $ret
  echo $ret
}

mkdir -p /tmp/feeds
pushd /tmp/feeds >/dev/null

# Download everything
msg "Downloading %d feeds" ${#@}
wget --timestamping --force-directories -nv $@

_feeds=($(find /tmp/feeds -type f))
for _feed in ${_feeds[@]}; do
# Get canonical link
  _url="$(xml sel -E utf-8 -T -t -m /rss/channel -v link "$_feed")"
  _uri="$(echo "$_url" | feed)"

  _posts=($(xml sel -E utf-8 -T -t -m /rss/channel/item -v link -n "$_feed"))
  _title="$(xml sel -E utf-8 -T -t -m /rss/channel -v title -n "$_feed")"
#  _type="$(feed_type "$_feed" "$_uri")"

  msg "%s" "$_title"
  msg "   %s" "$_url"

# If the feed is new, initialize a new thread
  if ! get "${_uri}" >/dev/null 2>&1; then
    msg "Initializing feed..."
    {
    xml sel -E utf-8 -T -t -m /rss/channel \
            -o "Subject: " -v title -n \
            -o "Message-Id: <$_uri@$HOSTNAME>" -n -n "$_feed" \
    && \
    xml sel -E utf-8 -T -t -m /rss/channel \
            -o "<h1>" -v title -o "</h1>" -n \
            -o "<p>" -v link -o "</p>" -n -n \
            -v description -n -n \
            "$_feed" | cleanup
    } | sendmail -t $USER
  fi

# Traverse all posts
  for _post in ${_posts[@]}; do

    _posturi="$(feed "${_post}")"

# Remove already processed post
    if get ${_posturi} >/dev/null ; then

      msg "Removing already seen: %s" "$_post"
      xml ed -L -d "/rss/channel/item/link[starts-with(text(),'$_post')]/.." "${_feed}"

# Process each post as an individual email
#    elif [ "$_type" = "content" ]; then
      continue
    fi
      if [ $(count "$_feed") -eq 0 ]; then
        continue
      fi

      _posturl="$(xml sel -N feedburner=http://rssnamespace.org/feedburner/ext/1.0 \
                          -E utf-8 -T \
                          -t -m "/rss/channel/item/link[starts-with(text(),'$_post')]/.." \
                          --if feedburner:origLink -v feedburner:origLink \
                          --else -v link "$_feed")"
      _license="$(xml sel -N creativeCommons=http://backend.userland.com/creativeCommonsRssModule \
                          -E utf-8 -T \
                          -t -m "/rss/channel/item/link[starts-with(text(),'$_post')]/.." \
                          -v creativeCommons:license "$_feed")"

      msg "Sending: %s" "$_posturl"
      {
      xml sel -E utf-8 -T -t -m "/rss/channel/item/link[starts-with(text(),'$_post')]/.." \
              -o "Subject: " -v title -n \
              -o "Message-Id: <" -v link -o ">" -n \
              -o "In-Reply-To: <$_uri@$HOSTNAME>" -n -n \
              "$_feed" \
      && \
      xml sel -N content=http://purl.org/rss/1.0/modules/content/ -E utf-8 -T \
              -t -m "/rss/channel/item/link[starts-with(text(),'$_post')]/.." \
              -o "<h1>" -v title -o "</h1>" -n \
              -o "<p>$_posturl</p>" -n -n \
              -o "<p>$_license</p>" -n -n \
              --if content:encoded -v content:encoded -n -n \
              --else -v description -n -n \
              "${_feed}" | cleanup
      } | sendmail -t $USER
#    fi
    
# Store
    put "$_posturi" "$(date +%s)"
  done

# If it's {summary,empty} send only one email per feed
# if [ "$_type" != "content" ]; then
#   if [ $(count "$_feed") -eq 0 ]; then
#     continue
#   fi

# msg "Generating digest"
# {
#   xml sel -E utf-8 -T -t -m "/rss/channel" \
#           -o "Subject: " -v title -n \
#           -o "Message-Id: <" -v link -o ">" -n \
#           -o "In-Reply-To: <$_uri@$HOSTNAME>" -n -n \
#           "$_feed" \
#   && \
#   xml sel -E utf-8 -T -N content=http://purl.org/rss/1.0/modules/content/ \
#           -t -m /rss/channel/item \
#           -o "<h2>" -v title -o "</h2>" -n \
#           -o "<p>" -v link -o "</p>" -n \
#           -v description -n -n \
#           "$_feed" | cleanup
# } | sendmail -t $USER
# fi


# Store and/or initialize
  put "$_uri" "$(date +%s)"
done
