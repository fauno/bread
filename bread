#!/bin/bash

export PATH=~/Proyectos/sendmail:$PATH

BREAD_HOME="${XDG_CONFIG_HOME:-${HOME}}/${0##*/}"
HASH_TABLE="${BREAD_HOME}/feeds.tch"
PANDOC_FLAGS="${PANDOC_FLAGS:-"--normalize --columns=72"}"

export PATH=$(dirname $(realpath ${0})):$PATH

[ ! -d "$BREAD_HOME" ] && mkdir -p "$BREAD_HOME"
[ ! -f "$HASH_TABLE" ] && tcamgr create "$HASH_TABLE"

# Echoes a message on stderr
msg() {
  printf "$1\n" "$2" >&2
}

# xml selection command
# shortcuts some RSS extensions
sel="xml sel -N content=http://purl.org/rss/1.0/modules/content/ \
             -N feedburner=http://rssnamespace.org/feedburner/ext/1.0 \
             -N creativeCommons=http://backend.userland.com/creativeCommonsRssModule \
             -N atom=http://www.w3.org/2005/Atom \
             -N rss=http://purl.org/rss/1.0/ \
             -E utf-8 -T "

# Get from hash table
get() {
  tcamgr get "${HASH_TABLE}" $1 2>/dev/null
  return $?
}

# Put on hash table
put() {
  tcamgr put "${HASH_TABLE}" $1 $2 2>/dev/null
  return $?
}

# Count items
count() {
  c=$($sel -t -v "count($2)" "$1" || echo 0)
  msg "Counting items: %d" $c

  echo $c
}

# Returns feed name from url
# accepts pipe and $1
feed() {
  if [ -z "$1" ] ; then
# TODO there's a more elegant way to do this
    while read u; do
      if echo "$u" | grep -q feedburner; then
        echo "$u.feedburner.com" | cut -d/ -f4
      else
        echo "$u" | cut -d/ -f3 | sed "s/^\(www\|blog\|static\)\.//"
      fi
    done
  else
    echo "$1" | feed
  fi
}

# Perform cleanups
# Currently removes feedburner ads, trackin params and uses pandoc to
# generate markdown emails
cleanup() {
  sed -e "/<div class=\"feedflare\">/,/<\/div>/d" \
      -e "s/utm_[^\&]\+//g" | \
  pandoc -f html -t markdown_strict ${PANDOC_FLAGS}
}

# Answers the second big question
# Pass $_feed as arg
rss_or_atom() {
  _type="$(xml el "$1" | head -n1)"
  echo $_type

  case $_type in
    feed)
      xml_basepath="/atom:feed"
      xml_itempath="$xml_basepath/atom:entry"
      xml_description="atom:subtitle"
      xml_url="atom:link[1]/@href"
      xml_title="atom:title"
      xml_date="atom:pubDate"
      xml_author="atom:author/atom:name"
      xml_content="content"
      xml_summary="atom:summary"
      xml_sel_post_by_url_prefix="$xml_itempath/atom:link[1][starts-with(@href,'"
      xml_sel_post_by_url_sufix="')]/.."
    ;;
    rss)
      xml_basepath="/rss/channel"
      xml_itempath="$xml_basepath/item"
      xml_description="description"
      xml_url="link"
      xml_title="title"
      xml_author="author"
      xml_date="updated"
      xml_content="content:encoded"
      xml_summary="description"
      xml_sel_post_by_url_prefix="${xml_itempath}/${xml_url}[starts-with(text(),'"
      xml_sel_post_by_url_sufix="')]/.."
    ;;
    rdf:RDF)
      xml_basepath="/rdf:RDF/rss:channel"
      xml_itempath="$xml_basepath/../rss:item"
      xml_description="rss:channel/rss:description"
      xml_date="rss:updated"
      xml_url="rss:link"
      xml_title="rss:title"
      xml_author="rss:author"
      xml_content="content:encoded"
      xml_summary="rss:description"
      xml_sel_post_by_url_prefix="${xml_itempath}/${xml_url}[starts-with(text(),'"
      xml_sel_post_by_url_sufix="')]/.."
    ;;
  esac
}

mkdir -p /tmp/feeds
pushd /tmp/feeds >/dev/null

# Download everything
msg "Downloading %d feeds" ${#@}
if type mwget &>/dev/null ; then
    if [ -f "$2" ]; then 
        cat "$2" | grep "^http" | mwget 10 --force-directories --timeout=10 --tries=3 -nv
    else
        echo "$@" | tr " " "\n" | grep "^http" | mwget 10 --force-directories --timeout=10 --tries=3 -nv
    fi
else
    wget --force-directories -nv --timeout=10 $@ --tries=3
fi

_feeds=($(find /tmp/feeds -type f))
for _feed in ${_feeds[@]}; do
# posts counter
  n=0
  rss_or_atom "$_feed"

# Get canonical link
  _url="$($sel -t -m "${xml_basepath}" -v "${xml_url}" "$_feed")"
  _uri="$(echo "$_url" | feed)"

  _posts=($($sel -t -m "${xml_itempath}" -v "${xml_url}" -n "$_feed"))
  _title="$($sel -t -m "${xml_basepath}" -v "${xml_title}" -n "$_feed")"
#  _type="$(feed_type "$_feed" "$_uri")"

  msg "%s" "$_title"
  msg "   %s" "$_url"

# Traverse all posts
  for _post in ${_posts[@]}; do

    _posturi="$(feed "${_post}")"

# Remove already processed post
    if get "${_posturi}" >/dev/null ; then

# Only useful for summaries
#      msg "Removing already seen: %s" "$_post"
#      xml ed -L -d "${xml_itempath}/${xml_url}[starts-with(text(),'$_post')]/.." "${_feed}"

# Only skip this post
      continue
    fi

    _posturl="$($sel -t -m "${xml_sel_post_by_url_prefix}${_post}${xml_sel_post_by_url_sufix}" \
                     --if feedburner:origLink -v feedburner:origLink \
                     --else -v "${xml_url}" "$_feed")"
    _license="$($sel -t -m "${xml_sel_post_by_url_prefix}${_post}${xml_sel_post_by_url_sufix}" \
                     -v creativeCommons:license "$_feed")"

    msg "Sending: %s" "$_posturl"
    {
    $sel -t -m "${xml_sel_post_by_url_prefix}${_post}${xml_sel_post_by_url_sufix}" \
         -o "From: <bread>" -n \
         -o "To: <$USER>" -n \
         -o "List-Id: ${_title} <$_uri>" -n \
         -o "Subject: " -v "${xml_title}" -n \
         -o "Message-Id: <" -v "${xml_url}" -o "_$(date +%Y%m%d%h%M%s)>" -n \
         -o "In-Reply-To: <${_uri}_$(date +%Y%m%d)@$HOSTNAME>" -n -n \
         "$_feed" \
    && \
    $sel -t -m "${xml_sel_post_by_url_prefix}${_post}${xml_sel_post_by_url_sufix}" \
         -o "<h1>" -v "${xml_title}" -o "</h1>" -n \
         -o "<p>$_posturl</p>" -n -n \
         -o "<p>$_license</p>" -n -n \
         --if "${xml_content}" -v "${xml_content}" -n -n \
         --else -v "${xml_summary}" -n -n \
         "${_feed}" | cleanup
    } | sendmail -t
    
# Store
    put "$_posturi" "$(date +%s)"
    let n=n+1
  done

  if [ $n -ne 0 ]; then
# Send an email that's the thread with new posts
    msg "Initializing feed..."
    {
    $sel -t -m "${xml_basepath}" \
         -o "From: " -v "${xml_title}" -o " <bread>" -n \
         -o "To: <$USER>" -n \
         -o "List-Id: ${_title} <$_uri>" -n \
         -o "Subject: " -v "${xml_title}" -n \
         -o "Message-Id: <${_uri}_$(date +%Y%m%d)@$HOSTNAME>" -n -n "$_feed" \
    && \
    $sel -t -m "${xml_basepath}" \
         -o "<h1>" -v "${xml_title}" -o "</h1>" -n \
         -o "<p>" -v "${xml_url}" -o "</p>" -n -n \
         -v "${xml_description}" -n -n \
         "$_feed" | cleanup
    } | sendmail -t
  fi

# Store and/or initialize
  put "$_uri" "$(date +%s)"
done
